# Operating System
## Lec4 Memory and Memory Management:
### 1. Background- a few reminders
- Program must be read (from disk) into memory and placed within a process for it to be run
- Main memory and registers are only storage CPU can access directly
- Memory unit only sees a stream of addresses + read requests, or address + data and write
requests
- Access to a register is in one CPU clock (or less)
- Access to main memory can take many cycles, causing a stall/wait
- Cache sits between main memory and CPU registers
- We need to protect access to memory to ensure correct operation
### 2. Logical and Physical memory addresses
The concept of a logical address space that is bound to a separate physical address space is central to proper memory management
Logical address – generated by the CPU; also referred to as virtual address
Physical address – address seen by the memory unit
Logical address space is the set of all logical addresses generated by a program
Physical address space is the set of all physical addresses generated by a program
### 3. Paging
- Although the logical address space appears contiguous, the equivalent physical address space probably isn’t.
- We want to be able to allocate physical memory wherever we can (the alternative is disk ‘memory’)
- Divide physical memory into fixed sized blocks (called **frames**)
  - Size is power of 2 (usually between 512 bytes and 16MBytes- in RISC-V usually 4KB blocks)
- Divide logical memory into blocks of the same size called **pages**
- Keep track of all the free frames in physical memory...
- So, to run a program of size N pages we need to find N free frames (in physical memory) to
load the program
- Set up a page table to **translate the logical to physical addresses**
### 4. Implementing a page table
- Page table is kept in main memory
- **Page-table base register (PTBR)** points to the page table <Points to bottom>
- **Page-table length register (PTLR)** indicates size of the page table (like an offset) <Points to top>
- In this scheme every data/instruction access requires two memory accesses
- One for the page table and one for the data / instruction
Interesting point:
- The two memory access problem can be solved by the use of a special fast-lookup hardware cache called **associative memory or translation look-aside buffers (TLBs)**
### 5. Sharing pages between processes
Shared code
- One copy of read-only (re-entrant) code shared among processes (i.e., text editors,
compilers, window systems)
- Similar to multiple threads sharing the same process space
- Also useful for interprocess communication if sharing of read-write pages is allowed
Private code and data
- Each process keeps a separate copy of the code and data
- The pages for the private code and data can appear anywhere in the logical address
space
### 6. Page Table Structure
Memory structures for paging can get huge using straight-forward methods
- Consider a 32-bit logical address space as on modern computers
- Page size of 4 KB (2^12)
- Page table would have 1 million entries (2^32 / 2^12)
- If each entry is 4 bytes -> 4 MB of physical address space / memory for page table alone
That amount of memory used to cost a lot
Don’t want to allocate that contiguously in main memory
OS developers have therefore created a few techniques to make this a bit more manageable:
- Hierarchical Paging
- Hashed Page Tables
- Inverted Page Tables